{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda8d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GitHub: abhishekajmera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8172cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USC ID: 8586888981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12165fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import hamming_loss, silhouette_score, accuracy_score\n",
    "import statistics\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1043f22",
   "metadata": {},
   "source": [
    "1.\n",
    "Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec125b",
   "metadata": {},
   "source": [
    "(a)\n",
    "Download the Anuran Calls (MFCCs) Data Set from:\n",
    "https://archive.ics.\n",
    "uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29\n",
    ". Choose 70% of the data\n",
    "randomly as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280162ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Frogs_MFCCs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6cb8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Family', 'Genus', 'Species']\n",
    "df.columns\n",
    "x_labs = ['MFCCs_ 1', 'MFCCs_ 2', 'MFCCs_ 3', 'MFCCs_ 4', 'MFCCs_ 5', 'MFCCs_ 6',\n",
    "       'MFCCs_ 7', 'MFCCs_ 8', 'MFCCs_ 9', 'MFCCs_10', 'MFCCs_11', 'MFCCs_12',\n",
    "       'MFCCs_13', 'MFCCs_14', 'MFCCs_15', 'MFCCs_16', 'MFCCs_17', 'MFCCs_18',\n",
    "       'MFCCs_19', 'MFCCs_20', 'MFCCs_21', 'MFCCs_22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aae7cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3)\n",
    "x_train = train[x_labs]\n",
    "y_train = train[labels]\n",
    "x_test = test[x_labs]\n",
    "y_test = test[labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83815ac",
   "metadata": {},
   "source": [
    "(b)\n",
    "Each instance has three labels: Families, Genus, and Species. Each of the labels\n",
    "has multiple classes. We wish to solve a multi-class and multi-label problem.\n",
    "One of the most important approaches to multi-label classification is to train a\n",
    "classifier for each label (binary relevance). We first try this approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566820c1",
   "metadata": {},
   "source": [
    "i.\n",
    "Research exact match and hamming score/ loss methods for evaluating multi-\n",
    "label classification and use them in evaluating the classifiers in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8837f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exact Match Score: It is a mteric in multilabel classification. \n",
    "#Exact Match Score defines the subset accuracy,which is the number of obs for which the actual set of labels\n",
    "#correspond to the predicted set of labels for that obervation. In other words, if the entire set of predicted\n",
    "#labels for a sample strictly match the actual set of labels, then the subset accuracy will be 1.0, otherwise it is 0.0.\n",
    "\n",
    "#Hamming Loss: Hamming Loss computes the average hamming distance between two set of samples. \n",
    "#It is the fraction of observations for which labels are not predicted properly.\n",
    "#In other words, if an observation has 3 labels, and 2 out of these 3 labels are not predicted correctly,\n",
    "#then the hamming distance is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd010099",
   "metadata": {},
   "source": [
    "ii.\n",
    "Train a SVM for each of the labels, using Gaussian kernels and one versus\n",
    "all classifiers. Determine the weight of the SVM penalty and the width of\n",
    "the Gaussian Kernel using 10 fold cross validation.\n",
    "1\n",
    "You are welcome to try\n",
    "to solve the problem with both standardized\n",
    "2\n",
    "and raw attributes and report\n",
    "the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131a6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = {}\n",
    "# avg_hamming_gaussian=[]\n",
    "# for i in labels:\n",
    "#     parameters = [{'kernel': ['rbf'],\n",
    "#                'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5],\n",
    "#                 'C': [1, 10, 100, 1000]}]\n",
    "#     clf = GridSearchCV(SVC(kernel='rbf',decision_function_shape='ovr'), parameters,cv=10)\n",
    "#     clf.fit(x_train, y_train[[i]].values.ravel())\n",
    "#     print(\"Best parameters :\".format(i))\n",
    "#     print()\n",
    "#     print(clf.best_params_)\n",
    "#     y_pred[i]= clf.predict(X_test)\n",
    "#     print(classification_report(y_test[[i]].values.ravel(), y_pred[i]))\n",
    "#     print(\"The hamming loss for class {} is {}\".format(i,hamming_loss(y_test[[i]], y_pred[i])))\n",
    "#     avg_hamming_gaussian.append(1- hamming_loss(y_test[[i]], y_pred[i]))\n",
    "    \n",
    "# df_match=pd.DataFrame()\n",
    "# for i in labels:\n",
    "#     df_match[i] = np.where(y_test[i] == y_pred[i],1,0)\n",
    "# df_match['sum'] = df_match[labels].sum(axis=1)\n",
    "# em = np.where(df_match['sum']==3,1.0,0).sum(axis=0)/len(df_match)\n",
    "# print(\"the exact match is: {}\".format(em))\n",
    "# print(\"Average Hamming Score is {}\".format(statistics.mean(avg_hamming_gaussian)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2713958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "c = np.logspace(-1, 4, 20)\n",
    "gammas = np.linspace(0.1, 2, 20)\n",
    "\n",
    "params = {'estimator__gamma':gammas, 'estimator__C':c}\n",
    "svm_model = OneVsRestClassifier(SVC(kernel='rbf', tol=0.1))\n",
    "gridModel = GridSearchCV(svm_model, param_grid=params, cv=KFold(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdc05d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Best SVM Penalty: 78.47599703514607\n",
      "Best Width of Gaussian Kernel: 0.5590169943749475\n",
      "Exact Match Loss: 0.0111162575266327\n",
      "Hamming Loss: 0.0111162575266327\n",
      "--------------------------------------------------------\n",
      "Genus\n",
      "Best SVM Penalty: 23.357214690901213\n",
      "Best Width of Gaussian Kernel: 0.5270462766947299\n",
      "Exact Match Loss: 0.014821676702176934\n",
      "Hamming Loss: 0.014821676702176934\n",
      "--------------------------------------------------------\n",
      "Species\n",
      "Best SVM Penalty: 42.81332398719391\n",
      "Best Width of Gaussian Kernel: 0.5129891760425771\n",
      "Exact Match Loss: 0.014358499305233918\n",
      "Hamming Loss: 0.014358499305233904\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in labels:\n",
    "    \n",
    "    print(i)\n",
    "    svm_mod = gridModel.fit(x_train, y_train[i])\n",
    "\n",
    "    best_parmas = svm_mod.best_params_\n",
    "\n",
    "    best_c = best_parmas['estimator__C']\n",
    "\n",
    "    best_gamma = best_parmas['estimator__gamma']\n",
    "\n",
    "    best_width = 1/np.sqrt(2*best_gamma)\n",
    "\n",
    "    print('Best SVM Penalty:', best_c)\n",
    "    print('Best Width of Gaussian Kernel:', best_width)\n",
    "\n",
    "    pred = svm_mod.predict(x_test)\n",
    "\n",
    "    exact_score = accuracy_score(pred, y_test[i])\n",
    "    exact_loss = 1-exact_score\n",
    "\n",
    "    hamming_losser = hamming_loss(pred, y_test[i])\n",
    "\n",
    "    print('Exact Match Loss:', exact_loss)\n",
    "    print('Hamming Loss:', hamming_losser)\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f694e",
   "metadata": {},
   "source": [
    "Standardized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58590827",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler = scaler.fit(df[x_labs])\n",
    "scaled_train_x = scaler.transform(x_train)\n",
    "scaled_test_x = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abbd0454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Best SVM Penalty: 2.0691380811147893\n",
      "Best Width of Gaussian Kernel: 2.23606797749979\n",
      "Exact Match Loss: 0.012968967114404872\n",
      "Hamming Loss: 0.012968967114404817\n",
      "--------------------------------------------------------\n",
      "Genus\n",
      "Best SVM Penalty: 3.79269019073225\n",
      "Best Width of Gaussian Kernel: 2.23606797749979\n",
      "Exact Match Loss: 0.015284854099119949\n",
      "Hamming Loss: 0.015284854099119963\n",
      "--------------------------------------------------------\n",
      "Species\n",
      "Best SVM Penalty: 2.0691380811147893\n",
      "Best Width of Gaussian Kernel: 2.23606797749979\n",
      "Exact Match Loss: 0.01806391848077815\n",
      "Hamming Loss: 0.018063918480778138\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in labels:\n",
    "    \n",
    "    print(i)\n",
    "    svm_mod = gridModel.fit(scaled_train_x, y_train[i])\n",
    "\n",
    "    best_parmas = svm_mod.best_params_\n",
    "\n",
    "    best_c = best_parmas['estimator__C']\n",
    "\n",
    "    best_gamma = best_parmas['estimator__gamma']\n",
    "\n",
    "    best_width = 1/np.sqrt(2*best_gamma)\n",
    "\n",
    "    \n",
    "    print('Best SVM Penalty:', best_c)\n",
    "    print('Best Width of Gaussian Kernel:', best_width)\n",
    "\n",
    "    pred = svm_mod.predict(scaled_test_x)\n",
    "\n",
    "    exact_score = accuracy_score(pred, y_test[i])\n",
    "    exact_loss = 1-exact_score\n",
    "\n",
    "    hamming_losser = hamming_loss(pred, y_test[i])\n",
    "\n",
    "    print('Exact Match Loss:', exact_loss)\n",
    "    print('Hamming Loss:', hamming_losser)\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e597186",
   "metadata": {},
   "source": [
    "iii.\n",
    "Repeat 1(b)ii with\n",
    "L\n",
    "1\n",
    "-penalized SVMs.\n",
    "3\n",
    "Remember to standardize\n",
    "4\n",
    "the at-\n",
    "tributes. Determine the weight of the SVM penalty using 10 fold cross vali-\n",
    "dation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50601121",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_mod = LinearSVC(penalty='l1', dual=False)\n",
    "params = {'C':c}\n",
    "l1GridModel = GridSearchCV(l_mod, params, cv=KFold(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b5b8ad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Best SVM Penalty: 1.1288378916846888\n",
      "Exact Match Loss: 0.05974988420565075\n",
      "Hamming Loss: 0.05974988420565076\n",
      "---------------------------------------\n",
      "Genus\n",
      "Best SVM Penalty: 143.8449888287663\n",
      "Exact Match Loss: 0.03983325613710054\n",
      "Hamming Loss: 0.03983325613710051\n",
      "---------------------------------------\n",
      "Species\n",
      "Best SVM Penalty: 3.79269019073225\n",
      "Exact Match Loss: 0.03427512737378413\n",
      "Hamming Loss: 0.03427512737378416\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for i in labels:\n",
    "    print(i)\n",
    "    l1_model = l1GridModel.fit(scaled_train_x, y_train[i])\n",
    "\n",
    "    best_params = l1_model.best_params_\n",
    "    best_c = best_params['C']\n",
    "\n",
    "    print('Best SVM Penalty:', best_c)\n",
    "\n",
    "    pred = l1_model.predict(scaled_test_x)\n",
    "    l1_score = accuracy_score(pred, y_test[i])\n",
    "    l1_loss = 1- l1_score\n",
    "\n",
    "    l1_hamming_loss = hamming_loss(pred, y_test[i])\n",
    "\n",
    "\n",
    "    print('Exact Match Loss:', l1_loss)\n",
    "    print('Hamming Loss:', l1_hamming_loss)\n",
    "    print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd649d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# smote = SMOTE()\n",
    "# familyTrainDataX, familyTrainDataY = smote.fit_sample(trainDataX, trainDataY['Family'])\n",
    "# genusTrainDataX, genusTrainDataY = smote.fit_sample(trainDataX, trainDataY['Genus'])\n",
    "# speciesTrainDataX, speciesTrainDataY = smote.fit_sample(trainDataX, trainDataY['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dbb05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote = SMOTE()\n",
    "# familyTrainDataX, familyTrainDataY = smote.fit_sample(trainDataX, trainDataY['Family'])\n",
    "# genusTrainDataX, genusTrainDataY = smote.fit_sample(trainDataX, trainDataY['Genus'])\n",
    "# speciesTrainDataX, speciesTrainDataY = smote.fit_sample(trainDataX, trainDataY['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29470c46",
   "metadata": {},
   "source": [
    "iv.\n",
    "Repeat 1(b)iii by using SMOTE or any other method you know to remedy\n",
    "class imbalance. Report your conclusions about the classifiers you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69da3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1SmoteSVMModel = LinearSVC(penalty='l1', dual=False)\n",
    "l1SmoteParameters = {'C':c}\n",
    "l1SmoteGridModel = GridSearchCV(l1SmoteSVMModel, l1SmoteParameters, cv=KFold(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d537a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Best SVM Penalty: 0.616\n",
      "Exact Match Loss: 0.0805928670680871\n",
      "Hamming Loss: 0.08059286706808708\n",
      "---------------------------------------------------------------------\n",
      "Genus\n",
      "Best SVM Penalty: 12.743\n",
      "Exact Match Loss: 0.09263547938860583\n",
      "Hamming Loss: 0.09263547938860583\n",
      "---------------------------------------------------------------------\n",
      "Species\n",
      "Best SVM Penalty: 263.665\n",
      "Exact Match Loss: 0.04770727188513202\n",
      "Hamming Loss: 0.047707271885132005\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "smote = SMOTE()\n",
    "for i in labels:\n",
    "    print(i)\n",
    "    smote_train_x, smote_train_y = smote.fit_resample(scaled_train_x, y_train[i])\n",
    "    smote_model = l1SmoteGridModel.fit(smote_train_x, smote_train_y)\n",
    "\n",
    "    best_params = smote_model.best_params_\n",
    "    best_c = best_params['C']\n",
    "    best_c = round(best_c, 3)\n",
    "    print('Best SVM Penalty:', best_c)\n",
    "\n",
    "    pred = smote_model.predict(scaled_test_x)\n",
    "    smote_score = accuracy_score(pred, y_test[i])\n",
    "    l1_smote_score = 1-smote_score\n",
    "\n",
    "    smote_hamming = hamming_loss(pred, y_test[i])\n",
    "\n",
    "\n",
    "    print('Exact Match Loss:', l1_smote_score)\n",
    "    print('Hamming Loss:', smote_hamming)\n",
    "    print('---------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa5a11",
   "metadata": {},
   "source": [
    "2.\n",
    "K-Means Clustering on a Multi-Class and Multi-Label Data Set\n",
    "Monte-Carlo Simulation:\n",
    "Perform the following procedures 50 times, and report\n",
    "the average and standard deviation of the 50 Hamming Distances that you calculate\n",
    "\n",
    "(a)\n",
    "Use k-means clustering on the whole Anuran Calls (MFCCs) Data Set (do not split\n",
    "the data into train and test, as we are not performing supervised learning in this\n",
    "exercise). Choose\n",
    "k\n",
    "∈ {\n",
    "1\n",
    ",\n",
    "2\n",
    ", . . . ,\n",
    "50\n",
    "}\n",
    "automatically based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee8deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import operator\n",
    "best_clust = {}\n",
    "for i in range(1, 51):\n",
    "    ss_score = {}\n",
    "    for k in range(2, 51):\n",
    "        kMeansModel = KMeans(n_clusters=k)\n",
    "        kMeansModel = kMeansModel.fit(df[x_labs])\n",
    "        clusterIndex = kMeansModel.labels_\n",
    "        score = silhouette_score(df[x_labs], clusterIndex)\n",
    "        ss_score[k] = score\n",
    "\n",
    "    score_sort = sorted(ss_score.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    bestCluster = score_sort[0][0]\n",
    "    best_clust[i] = bestCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d82e911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08f79e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Optimal cluster no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iteration 1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iteration 2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iteration 3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iteration 4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iteration 5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iteration 6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iteration 7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iteration 8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iteration 9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iteration 10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iteration 11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Iteration 12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iteration 13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iteration 14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iteration 15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iteration 16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iteration 17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iteration 18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Iteration 19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Iteration 20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Iteration 21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Iteration 22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Iteration 23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iteration 24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Iteration 25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iteration 26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Iteration 27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Iteration 28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Iteration 29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Iteration 30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Iteration 31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Iteration 32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Iteration 33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Iteration 34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Iteration 35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Iteration 36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Iteration 37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Iteration 38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Iteration 39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Iteration 40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Iteration 41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Iteration 42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Iteration 43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Iteration 44</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Iteration 45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Iteration 46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Iteration 47</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Iteration 48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Iteration 49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Iteration 50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Iteration  Optimal cluster no\n",
       "0    Iteration 1                   4\n",
       "1    Iteration 2                   4\n",
       "2    Iteration 3                   4\n",
       "3    Iteration 4                   4\n",
       "4    Iteration 5                   4\n",
       "5    Iteration 6                   4\n",
       "6    Iteration 7                   4\n",
       "7    Iteration 8                   4\n",
       "8    Iteration 9                   4\n",
       "9   Iteration 10                   4\n",
       "10  Iteration 11                   4\n",
       "11  Iteration 12                   4\n",
       "12  Iteration 13                   4\n",
       "13  Iteration 14                   4\n",
       "14  Iteration 15                   4\n",
       "15  Iteration 16                   4\n",
       "16  Iteration 17                   4\n",
       "17  Iteration 18                   4\n",
       "18  Iteration 19                   4\n",
       "19  Iteration 20                   4\n",
       "20  Iteration 21                   4\n",
       "21  Iteration 22                   4\n",
       "22  Iteration 23                   4\n",
       "23  Iteration 24                   4\n",
       "24  Iteration 25                   4\n",
       "25  Iteration 26                   4\n",
       "26  Iteration 27                   4\n",
       "27  Iteration 28                   4\n",
       "28  Iteration 29                   4\n",
       "29  Iteration 30                   4\n",
       "30  Iteration 31                   4\n",
       "31  Iteration 32                   4\n",
       "32  Iteration 33                   4\n",
       "33  Iteration 34                   4\n",
       "34  Iteration 35                   4\n",
       "35  Iteration 36                   4\n",
       "36  Iteration 37                   4\n",
       "37  Iteration 38                   4\n",
       "38  Iteration 39                   4\n",
       "39  Iteration 40                   4\n",
       "40  Iteration 41                   4\n",
       "41  Iteration 42                   4\n",
       "42  Iteration 43                   4\n",
       "43  Iteration 44                   4\n",
       "44  Iteration 45                   4\n",
       "45  Iteration 46                   4\n",
       "46  Iteration 47                   4\n",
       "47  Iteration 48                   4\n",
       "48  Iteration 49                   4\n",
       "49  Iteration 50                   4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_data = []\n",
    "for i in range(1, 51):\n",
    "    inst = []\n",
    "    inst.append('Iteration ' + str(i))\n",
    "    inst.append(best_clust[i])\n",
    "    tab_data.append(inst)\n",
    "pd.DataFrame(tab_data, columns = ['Iteration', 'Optimal cluster no'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72949284",
   "metadata": {},
   "source": [
    "(b)\n",
    "In each cluster, determine which family is the majority by reading the true labels.\n",
    "Repeat for genus and species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afbedf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_index = {}\n",
    "for i in range(1, 51):\n",
    "    mod_fin = KMeans(n_clusters=bestCluster)\n",
    "    mod_fin = mod_fin.fit(df[x_labs])\n",
    "    cluter_indexed = mod_fin.labels_\n",
    "    clust_index[i] = cluter_indexed\n",
    "\n",
    "tab_data = []\n",
    "for itera in range(1, 51):\n",
    "    bestCluster = best_clust[itera]\n",
    "    cluter_indexed = clust_index[itera]\n",
    "    clusterLabel = []\n",
    "    for i in range(0, bestCluster):\n",
    "        family = {}\n",
    "        genus = {}\n",
    "        species = {}\n",
    "        for j in range(0, len(df[labels])):\n",
    "            if cluter_indexed[j]==i:\n",
    "                fam = df['Family'][j]\n",
    "                if fam in family.keys():\n",
    "                    family[fam] += 1\n",
    "                else:\n",
    "                    family[fam] = 1\n",
    "\n",
    "                gen = df['Genus'][j]\n",
    "                if gen in genus.keys():\n",
    "                    genus[gen] += 1\n",
    "                else:\n",
    "                    genus[gen] = 1\n",
    "\n",
    "                specy = df['Species'][j]\n",
    "                if specy in species.keys():\n",
    "                    species[specy] += 1\n",
    "                else:\n",
    "                    species[specy] = 1\n",
    "\n",
    "        fam_sort = sorted(family.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        sort_gen = sorted(genus.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        species_sort = sorted(species.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "        fam_lab = fam_sort[0][0]\n",
    "        gen_lab = sort_gen[0][0]\n",
    "        spec_lab = species_sort[0][0]\n",
    "\n",
    "        label = {}\n",
    "        label['Family'] = fam_lab\n",
    "        label['Genus'] = gen_lab\n",
    "        label['Species'] = spec_lab\n",
    "        clusterLabel.append(label)\n",
    "  \n",
    "    for i in range(0, bestCluster):\n",
    "        row = []\n",
    "        row.append('Iteration ' + str(itera))\n",
    "        row.append('Cluster ' + str(i+1))\n",
    "        row.append(clusterLabel[i]['Family'])\n",
    "        row.append(clusterLabel[i]['Genus'])\n",
    "        row.append(clusterLabel[i]['Species'])\n",
    "        tab_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75ec6a9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iteration 1</td>\n",
       "      <td>Cluster 1</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iteration 1</td>\n",
       "      <td>Cluster 2</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iteration 1</td>\n",
       "      <td>Cluster 3</td>\n",
       "      <td>Dendrobatidae</td>\n",
       "      <td>Ameerega</td>\n",
       "      <td>Ameeregatrivittata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iteration 1</td>\n",
       "      <td>Cluster 4</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCinerascens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iteration 2</td>\n",
       "      <td>Cluster 1</td>\n",
       "      <td>Dendrobatidae</td>\n",
       "      <td>Ameerega</td>\n",
       "      <td>Ameeregatrivittata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Iteration 49</td>\n",
       "      <td>Cluster 4</td>\n",
       "      <td>Dendrobatidae</td>\n",
       "      <td>Ameerega</td>\n",
       "      <td>Ameeregatrivittata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Iteration 50</td>\n",
       "      <td>Cluster 1</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Iteration 50</td>\n",
       "      <td>Cluster 2</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Iteration 50</td>\n",
       "      <td>Cluster 3</td>\n",
       "      <td>Dendrobatidae</td>\n",
       "      <td>Ameerega</td>\n",
       "      <td>Ameeregatrivittata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Iteration 50</td>\n",
       "      <td>Cluster 4</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCinerascens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Iteration    Cluster           Family      Genus  \\\n",
       "0     Iteration 1  Cluster 1  Leptodactylidae  Adenomera   \n",
       "1     Iteration 1  Cluster 2          Hylidae  Hypsiboas   \n",
       "2     Iteration 1  Cluster 3    Dendrobatidae   Ameerega   \n",
       "3     Iteration 1  Cluster 4          Hylidae  Hypsiboas   \n",
       "4     Iteration 2  Cluster 1    Dendrobatidae   Ameerega   \n",
       "..            ...        ...              ...        ...   \n",
       "195  Iteration 49  Cluster 4    Dendrobatidae   Ameerega   \n",
       "196  Iteration 50  Cluster 1          Hylidae  Hypsiboas   \n",
       "197  Iteration 50  Cluster 2  Leptodactylidae  Adenomera   \n",
       "198  Iteration 50  Cluster 3    Dendrobatidae   Ameerega   \n",
       "199  Iteration 50  Cluster 4          Hylidae  Hypsiboas   \n",
       "\n",
       "                    Species  \n",
       "0    AdenomeraHylaedactylus  \n",
       "1         HypsiboasCordobae  \n",
       "2        Ameeregatrivittata  \n",
       "3      HypsiboasCinerascens  \n",
       "4        Ameeregatrivittata  \n",
       "..                      ...  \n",
       "195      Ameeregatrivittata  \n",
       "196       HypsiboasCordobae  \n",
       "197  AdenomeraHylaedactylus  \n",
       "198      Ameeregatrivittata  \n",
       "199    HypsiboasCinerascens  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tab_data, columns = ['Iteration','Cluster','Family','Genus','Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef72e40b",
   "metadata": {},
   "source": [
    "(c)\n",
    "Now for each cluster you have a majority label triplet (family, genus, species).\n",
    "Calculate the average Hamming distance, Hamming score, and Hamming loss\n",
    "5\n",
    "between the true labels and the labels assigned by clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e497f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_ham_loss = []\n",
    "avg_ham_score = []\n",
    "for iteration in range(1,51):\n",
    "    clusterIndex = clust_index[iteration]\n",
    "    pred_fam = []\n",
    "    pred_gen = []\n",
    "    pred_spec = []\n",
    "    for i in range(0, len(df[labels])):\n",
    "        clusterName = clusterIndex[i]\n",
    "        label = clusterLabel[clusterName]\n",
    "        fam_label = label['Family']\n",
    "        gen_lab = label['Genus']\n",
    "        spec_lab = label['Species']\n",
    "\n",
    "        pred_fam.append(fam_label)\n",
    "        pred_gen.append(gen_lab)\n",
    "        pred_spec.append(spec_lab)\n",
    "\n",
    "    fam_act = np.array(df['Family'])\n",
    "    act_gen = np.array(df['Genus'])\n",
    "    act_spec = np.array(df['Species'])\n",
    "\n",
    "    pred_fam = np.array(pred_fam)\n",
    "    pred_gen = np.array(pred_gen)\n",
    "    pred_spec = np.array(pred_spec)\n",
    "\n",
    "    fam_ham_loss = hamming_loss(pred_fam, fam_act)\n",
    "\n",
    "    fam_ham_score = accuracy_score(pred_fam, fam_act)\n",
    "\n",
    "\n",
    "    gen_ham_loss = hamming_loss(pred_gen, act_gen)\n",
    "\n",
    "    gen_ham_score = accuracy_score(pred_gen, act_gen)\n",
    "\n",
    "\n",
    "    spec_ham_loss = hamming_loss(pred_spec, act_spec)\n",
    "\n",
    "    spac_ham_score = accuracy_score(pred_spec, act_spec)\n",
    "\n",
    "    \n",
    "    avg_ham_loss_iter = (fam_ham_loss + gen_ham_loss + spec_ham_loss)/3\n",
    "\n",
    "    avg_ham_score_iter = (fam_ham_score + gen_ham_score + spac_ham_score)/3\n",
    "\n",
    "    \n",
    "    avg_ham_loss.append(avg_ham_loss_iter)\n",
    "    avg_ham_score.append(avg_ham_score_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22ff669f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# avgHammingScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c4e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgHammingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "419a024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Avg hamming loss</th>\n",
       "      <th>Avg hamming score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iteration 1</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.195506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iteration 2</td>\n",
       "      <td>0.428307</td>\n",
       "      <td>0.571693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iteration 3</td>\n",
       "      <td>0.222423</td>\n",
       "      <td>0.777577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iteration 4</td>\n",
       "      <td>0.888070</td>\n",
       "      <td>0.111930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iteration 5</td>\n",
       "      <td>0.285152</td>\n",
       "      <td>0.714848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iteration 6</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.112717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iteration 7</td>\n",
       "      <td>0.936669</td>\n",
       "      <td>0.063331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iteration 8</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.112717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iteration 9</td>\n",
       "      <td>0.760806</td>\n",
       "      <td>0.239194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iteration 10</td>\n",
       "      <td>0.816169</td>\n",
       "      <td>0.183831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iteration 11</td>\n",
       "      <td>0.834607</td>\n",
       "      <td>0.165393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Iteration 12</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.554876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iteration 13</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.112717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iteration 14</td>\n",
       "      <td>0.816169</td>\n",
       "      <td>0.183831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iteration 15</td>\n",
       "      <td>0.892286</td>\n",
       "      <td>0.107714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iteration 16</td>\n",
       "      <td>0.400834</td>\n",
       "      <td>0.599166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iteration 17</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.554876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iteration 18</td>\n",
       "      <td>0.869076</td>\n",
       "      <td>0.130924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Iteration 19</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.554876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Iteration 20</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.112717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Iteration 21</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.112717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Iteration 22</td>\n",
       "      <td>0.885893</td>\n",
       "      <td>0.114107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Iteration 23</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.112717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iteration 24</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.195506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Iteration 25</td>\n",
       "      <td>0.354644</td>\n",
       "      <td>0.645356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iteration 26</td>\n",
       "      <td>0.222423</td>\n",
       "      <td>0.777577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Iteration 27</td>\n",
       "      <td>0.428307</td>\n",
       "      <td>0.571693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Iteration 28</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.112717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Iteration 29</td>\n",
       "      <td>0.285291</td>\n",
       "      <td>0.714709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Iteration 30</td>\n",
       "      <td>0.221913</td>\n",
       "      <td>0.778087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Iteration 31</td>\n",
       "      <td>0.937225</td>\n",
       "      <td>0.062775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Iteration 32</td>\n",
       "      <td>0.295112</td>\n",
       "      <td>0.704888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Iteration 33</td>\n",
       "      <td>0.428307</td>\n",
       "      <td>0.571693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Iteration 34</td>\n",
       "      <td>0.354922</td>\n",
       "      <td>0.645078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Iteration 35</td>\n",
       "      <td>0.888070</td>\n",
       "      <td>0.111930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Iteration 36</td>\n",
       "      <td>0.880751</td>\n",
       "      <td>0.119249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Iteration 37</td>\n",
       "      <td>0.354644</td>\n",
       "      <td>0.645356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Iteration 38</td>\n",
       "      <td>0.222423</td>\n",
       "      <td>0.777577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Iteration 39</td>\n",
       "      <td>0.285430</td>\n",
       "      <td>0.714570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Iteration 40</td>\n",
       "      <td>0.816169</td>\n",
       "      <td>0.183831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Iteration 41</td>\n",
       "      <td>0.318647</td>\n",
       "      <td>0.681353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Iteration 42</td>\n",
       "      <td>0.976372</td>\n",
       "      <td>0.023628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Iteration 43</td>\n",
       "      <td>0.440723</td>\n",
       "      <td>0.559277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Iteration 44</td>\n",
       "      <td>0.885893</td>\n",
       "      <td>0.114107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Iteration 45</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.112717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Iteration 46</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.112069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Iteration 47</td>\n",
       "      <td>0.936715</td>\n",
       "      <td>0.063285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Iteration 48</td>\n",
       "      <td>0.440723</td>\n",
       "      <td>0.559277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Iteration 49</td>\n",
       "      <td>0.936715</td>\n",
       "      <td>0.063285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Iteration 50</td>\n",
       "      <td>0.221774</td>\n",
       "      <td>0.778226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Iteration  Avg hamming loss  Avg hamming score\n",
       "0    Iteration 1          0.804494           0.195506\n",
       "1    Iteration 2          0.428307           0.571693\n",
       "2    Iteration 3          0.222423           0.777577\n",
       "3    Iteration 4          0.888070           0.111930\n",
       "4    Iteration 5          0.285152           0.714848\n",
       "5    Iteration 6          0.887283           0.112717\n",
       "6    Iteration 7          0.936669           0.063331\n",
       "7    Iteration 8          0.887283           0.112717\n",
       "8    Iteration 9          0.760806           0.239194\n",
       "9   Iteration 10          0.816169           0.183831\n",
       "10  Iteration 11          0.834607           0.165393\n",
       "11  Iteration 12          0.445124           0.554876\n",
       "12  Iteration 13          0.887283           0.112717\n",
       "13  Iteration 14          0.816169           0.183831\n",
       "14  Iteration 15          0.892286           0.107714\n",
       "15  Iteration 16          0.400834           0.599166\n",
       "16  Iteration 17          0.445124           0.554876\n",
       "17  Iteration 18          0.869076           0.130924\n",
       "18  Iteration 19          0.445124           0.554876\n",
       "19  Iteration 20          0.887283           0.112717\n",
       "20  Iteration 21          0.887283           0.112717\n",
       "21  Iteration 22          0.885893           0.114107\n",
       "22  Iteration 23          0.887283           0.112717\n",
       "23  Iteration 24          0.804494           0.195506\n",
       "24  Iteration 25          0.354644           0.645356\n",
       "25  Iteration 26          0.222423           0.777577\n",
       "26  Iteration 27          0.428307           0.571693\n",
       "27  Iteration 28          0.887283           0.112717\n",
       "28  Iteration 29          0.285291           0.714709\n",
       "29  Iteration 30          0.221913           0.778087\n",
       "30  Iteration 31          0.937225           0.062775\n",
       "31  Iteration 32          0.295112           0.704888\n",
       "32  Iteration 33          0.428307           0.571693\n",
       "33  Iteration 34          0.354922           0.645078\n",
       "34  Iteration 35          0.888070           0.111930\n",
       "35  Iteration 36          0.880751           0.119249\n",
       "36  Iteration 37          0.354644           0.645356\n",
       "37  Iteration 38          0.222423           0.777577\n",
       "38  Iteration 39          0.285430           0.714570\n",
       "39  Iteration 40          0.816169           0.183831\n",
       "40  Iteration 41          0.318647           0.681353\n",
       "41  Iteration 42          0.976372           0.023628\n",
       "42  Iteration 43          0.440723           0.559277\n",
       "43  Iteration 44          0.885893           0.114107\n",
       "44  Iteration 45          0.887283           0.112717\n",
       "45  Iteration 46          0.887931           0.112069\n",
       "46  Iteration 47          0.936715           0.063285\n",
       "47  Iteration 48          0.440723           0.559277\n",
       "48  Iteration 49          0.936715           0.063285\n",
       "49  Iteration 50          0.221774           0.778226"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_dat = []\n",
    "for i in range(1, 51):\n",
    "    row = []\n",
    "    row.append('Iteration ' + str(i))\n",
    "    row.append(avg_ham_loss[i-1])\n",
    "    row.append(avg_ham_score[i-1])\n",
    "    tab_dat.append(row)\n",
    "pd.DataFrame(tab_dat, columns = ['Iteration','Avg hamming loss','Avg hamming score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4726a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ham_loss = statistics.mean(avg_ham_loss)\n",
    "\n",
    "\n",
    "std_ham_loss = statistics.stdev(avg_ham_loss)\n",
    "\n",
    "\n",
    "mean_ham_score = statistics.mean(avg_ham_score)\n",
    "\n",
    "\n",
    "std_ham_score = statistics.stdev(avg_ham_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "865b457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642004169562196"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ham_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3797136d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27610378440131333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_ham_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14f00b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35799583043780403"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ham_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "227f3dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27610378440131333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_ham_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20a96ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISLR 12.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52ece238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dis_mat = np.array([[0.0, 0.3, 0.4, 0.7], [0.3, 0.0, 0.5, 0.8], [0.4, 0.5, 0.0, 0.45], [0.7, 0.8, 0.45, 0.0]])\n",
    "distances = squareform(dis_mat)\n",
    "link_mat = linkage(distances, \"complete\")\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(111)\n",
    "dendrogram(link_mat, labels=[\"1\", \"2\", \"3\", \"4\"])\n",
    "plt.title(\"Dendrogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8e1665d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "link_mat = linkage(dists, \"single\")\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(111)\n",
    "dendrogram(link_mat, labels=[\"1\", \"2\", \"3\", \"4\"])\n",
    "plt.title(\"Dendrogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29efef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Obs 1 and 2 are in cluster A and 3 and 4 in cluster B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "21c178b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Obs 1, 2 and 3 are in cluster A and 4 in cluster B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2a922223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dis_mat = np.array([[0.0, 0.3, 0.4, 0.7], [0.3, 0.0, 0.5, 0.8], [0.4, 0.5, 0.0, 0.45], [0.7, 0.8, 0.45, 0.0]])\n",
    "distances = squareform(dis_mat)\n",
    "link_mat = linkage(distances, \"complete\")\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(111)\n",
    "dendrogram(link_mat, labels=[\"1\", \"4\", \"3\", \"2\"])\n",
    "plt.title(\"Dendrogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c77fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
